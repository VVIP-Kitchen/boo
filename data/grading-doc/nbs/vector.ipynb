{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from typing import List, Tuple\n",
    "from tqdm.notebook import tqdm\n",
    "from fastembed import TextEmbedding\n",
    "from qdrant_client.http import models\n",
    "from qdrant_client import QdrantClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_refined_content(file_path: str) -> str:\n",
    "  with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subjects(content: str) -> List[Tuple[str, str]]:\n",
    "  # Split the content by \"##\" headers\n",
    "  subjects = re.split(r'\\n##\\s', content)\n",
    "  \n",
    "  # The first element might be empty or contain text before the first \"##\"\n",
    "  if not subjects[0].strip():\n",
    "    subjects = subjects[1:]\n",
    "  elif not subjects[0].startswith(\"##\"):\n",
    "    subjects[0] = \"## \" + subjects[0]\n",
    "  \n",
    "  # Pair each header with its content\n",
    "  return [(subject.split('\\n', 1)[0], subject) for subject in subjects]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(subjects: List[Tuple[str, str]]) -> List[Tuple[str, List[float]]]:\n",
    "  embedding_model = TextEmbedding()\n",
    "  embeddings = []\n",
    "  \n",
    "  for header, content in tqdm(subjects, desc=\"Generating embeddings\"):\n",
    "    embedding = next(embedding_model.embed([content]))\n",
    "    embeddings.append((header, embedding.tolist()))\n",
    "  \n",
    "  return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_in_qdrant(embeddings: List[Tuple[str, List[float]]], collection_name: str, subjects: List[Tuple[str, str]]):\n",
    "  api_key = os.getenv('QDRANT_API_KEY')\n",
    "  endpoint = os.getenv('QDRANT_ENDPOINT')\n",
    "  \n",
    "  if not api_key or not endpoint:\n",
    "    raise ValueError(\"Please set the QDRANT_API_KEY and QDRANT_ENDPOINT environment variables\")\n",
    "  \n",
    "  client = QdrantClient(url=endpoint, api_key=api_key)\n",
    "  \n",
    "  collections = client.get_collections().collections\n",
    "  if not any(collection.name == collection_name for collection in collections):\n",
    "    client.create_collection(\n",
    "      collection_name=collection_name,\n",
    "      vectors_config=models.VectorParams(size=384, distance=models.Distance.COSINE),\n",
    "    )\n",
    "  \n",
    "  points = [\n",
    "    models.PointStruct(\n",
    "      id=i,\n",
    "      vector=embedding,\n",
    "      payload={\"header\": header, \"content\": content}\n",
    "    )\n",
    "    for i, ((header, content), embedding) in enumerate(zip(subjects, [emb for _, emb in embeddings]))\n",
    "  ]\n",
    "  \n",
    "  batch_size = 100\n",
    "  for i in tqdm(range(0, len(points), batch_size), desc=\"Storing in Qdrant\"):\n",
    "    batch = points[i:i+batch_size]\n",
    "    client.upsert(collection_name=collection_name, points=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(input_file: str, collection_name: str):\n",
    "  content = read_refined_content(input_file)\n",
    "  \n",
    "  subjects = extract_subjects(content)\n",
    "  print(f\"Extracted {len(subjects)} subjects\")\n",
    "  \n",
    "  embeddings = generate_embeddings(subjects)\n",
    "  \n",
    "  store_in_qdrant(embeddings, collection_name, subjects)\n",
    "  print(\"Finished storing embeddings in Qdrant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 52 subjects\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f06c8d89b024536bbf8399483f43e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e2ed0c2a97740d6a6576184f71f2dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50142b3d3602403da4b5e2099da094b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Storing in Qdrant:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished storing embeddings in Qdrant\n"
     ]
    }
   ],
   "source": [
    "input_file = \"../markdowns/grading_doc-edit.md\"\n",
    "collection_name = \"grading-doc\"\n",
    "\n",
    "main(input_file, collection_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
